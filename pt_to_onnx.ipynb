{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyNlAkE9C5+Li0hhr03Ayc7F",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/sudeepmenon17/PytorchforNN/blob/main/pt_to_onnx.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install google-auth\n",
        "from google.colab import auth\n",
        "from google.colab import drive\n",
        "\n",
        "drive.mount('/content/drive')\n",
        "\n",
        "# !pip install torchvision\n",
        "!pip install onnx"
      ],
      "metadata": {
        "id": "RJJeKlFYL8UK",
        "outputId": "0f33937f-2c15-45d3-f041-dfd7196f6658",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: google-auth in /usr/local/lib/python3.10/dist-packages (2.27.0)\n",
            "Requirement already satisfied: cachetools<6.0,>=2.0.0 in /usr/local/lib/python3.10/dist-packages (from google-auth) (5.5.0)\n",
            "Requirement already satisfied: pyasn1-modules>=0.2.1 in /usr/local/lib/python3.10/dist-packages (from google-auth) (0.4.1)\n",
            "Requirement already satisfied: rsa<5,>=3.1.4 in /usr/local/lib/python3.10/dist-packages (from google-auth) (4.9)\n",
            "Requirement already satisfied: pyasn1<0.7.0,>=0.4.6 in /usr/local/lib/python3.10/dist-packages (from pyasn1-modules>=0.2.1->google-auth) (0.6.1)\n",
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n",
            "Requirement already satisfied: onnx in /usr/local/lib/python3.10/dist-packages (1.17.0)\n",
            "Requirement already satisfied: numpy>=1.20 in /usr/local/lib/python3.10/dist-packages (from onnx) (1.26.4)\n",
            "Requirement already satisfied: protobuf>=3.20.2 in /usr/local/lib/python3.10/dist-packages (from onnx) (4.25.5)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 16,
      "metadata": {
        "id": "Hcs4_S9aKaOS"
      },
      "outputs": [],
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.onnx\n",
        "from torch.autograd import Variable\n",
        "\n",
        "# Define the PyTorch model class\n",
        "class Model(nn.Module):\n",
        "    def __init__(self, in_features=5, h1=61, h2=60, out_features=1):\n",
        "        super(Model, self).__init__()\n",
        "        self.fc1 = nn.Linear(in_features, h1)\n",
        "        self.fc2 = nn.Linear(h1, h2)\n",
        "        self.out = nn.Linear(h2, out_features)\n",
        "        self.sigmoid = nn.Sigmoid()\n",
        "\n",
        "    def forward(self, x):\n",
        "        x = self.sigmoid(self.fc1(x))\n",
        "        x = self.sigmoid(self.fc2(x))\n",
        "        x = self.out(x)\n",
        "        return x"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Load the saved PyTorch model\n",
        "model = Model()\n",
        "model.load_state_dict(torch.load('/content/drive/MyDrive/komegaSST_data/airfoil_model.pt'))\n",
        "model.eval()"
      ],
      "metadata": {
        "id": "lxfC9ZVwMKYV",
        "outputId": "a33f08af-7f52-488a-b2d8-e15bdae480d7",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-17-fb4db81e98fc>:3: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
            "  model.load_state_dict(torch.load('/content/drive/MyDrive/komegaSST_data/airfoil_model.pt'))\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "Model(\n",
              "  (fc1): Linear(in_features=5, out_features=61, bias=True)\n",
              "  (fc2): Linear(in_features=61, out_features=60, bias=True)\n",
              "  (out): Linear(in_features=60, out_features=1, bias=True)\n",
              "  (sigmoid): Sigmoid()\n",
              ")"
            ]
          },
          "metadata": {},
          "execution_count": 17
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Define file paths\n",
        "onnx_file_path = \"/content/drive/MyDrive/komegaSST_data/airfoil_model.onnx\"\n",
        "dummy_input = torch.randn(1,5)\n",
        "\n",
        "# Step 1: Export PyTorch model to ONNX format\n",
        "def export_pytorch_to_onnx(model, dummy_input, onnx_file_path):\n",
        "    torch.onnx.export(\n",
        "        model,\n",
        "        dummy_input,\n",
        "        onnx_file_path,\n",
        "        export_params=True,\n",
        "        opset_version=11,\n",
        "        do_constant_folding=True,\n",
        "        input_names=['input'],\n",
        "        output_names=['output']\n",
        "    )"
      ],
      "metadata": {
        "id": "s1r-6AlFMyNx"
      },
      "execution_count": 18,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Perform the conversion\n",
        "export_pytorch_to_onnx(model, dummy_input, onnx_file_path)\n"
      ],
      "metadata": {
        "id": "ybMl7I07NEEc"
      },
      "execution_count": 19,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install onnxruntime\n",
        "import numpy as np\n",
        "import onnxruntime\n",
        "import torch\n",
        "\n",
        "# Define a function to check the consistency of the two models\n",
        "def compare_pytorch_onnx(pytorch_model, onnx_model_path, dummy_input):\n",
        "    # Ensure PyTorch model is in evaluation mode\n",
        "    pytorch_model.eval()\n",
        "\n",
        "    # Get the PyTorch model's output\n",
        "    with torch.no_grad():\n",
        "        pytorch_output = pytorch_model(dummy_input)\n",
        "\n",
        "    # Load ONNX model using ONNX Runtime\n",
        "    session = onnxruntime.InferenceSession(onnx_model_path)\n",
        "\n",
        "    # Prepare input for the ONNX model\n",
        "    dummy_input_numpy = dummy_input.numpy()  # Convert PyTorch tensor to NumPy array\n",
        "    input_name = session.get_inputs()[0].name\n",
        "    output_name = session.get_outputs()[0].name\n",
        "\n",
        "    # Get the ONNX model's output\n",
        "    onnx_output = session.run([output_name], {input_name: dummy_input_numpy})[0]\n",
        "\n",
        "    # Compare outputs\n",
        "    print(\"PyTorch Model Output:\", pytorch_output.numpy())\n",
        "    print(\"ONNX Model Output:\", onnx_output)\n",
        "    print(\"Difference:\", np.abs(pytorch_output.numpy() - onnx_output))\n",
        "    print(\"Are the outputs close?:\", np.allclose(pytorch_output.numpy(), onnx_output, atol=1e-5))\n",
        "\n",
        "# Define a dummy input\n",
        "dummy_input = torch.randn(1, 5)\n",
        "\n",
        "# Compare PyTorch and ONNX outputs\n",
        "compare_pytorch_onnx(model, onnx_file_path, dummy_input)\n"
      ],
      "metadata": {
        "id": "D_LoB9mMPGX3",
        "outputId": "1552b880-5005-48e5-ad0b-ae296c723439",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 21,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: onnxruntime in /usr/local/lib/python3.10/dist-packages (1.20.1)\n",
            "Requirement already satisfied: coloredlogs in /usr/local/lib/python3.10/dist-packages (from onnxruntime) (15.0.1)\n",
            "Requirement already satisfied: flatbuffers in /usr/local/lib/python3.10/dist-packages (from onnxruntime) (24.3.25)\n",
            "Requirement already satisfied: numpy>=1.21.6 in /usr/local/lib/python3.10/dist-packages (from onnxruntime) (1.26.4)\n",
            "Requirement already satisfied: packaging in /usr/local/lib/python3.10/dist-packages (from onnxruntime) (24.2)\n",
            "Requirement already satisfied: protobuf in /usr/local/lib/python3.10/dist-packages (from onnxruntime) (4.25.5)\n",
            "Requirement already satisfied: sympy in /usr/local/lib/python3.10/dist-packages (from onnxruntime) (1.13.1)\n",
            "Requirement already satisfied: humanfriendly>=9.1 in /usr/local/lib/python3.10/dist-packages (from coloredlogs->onnxruntime) (10.0)\n",
            "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /usr/local/lib/python3.10/dist-packages (from sympy->onnxruntime) (1.3.0)\n",
            "PyTorch Model Output: [[0.98726714]]\n",
            "ONNX Model Output: [[0.98726726]]\n",
            "Difference: [[1.1920929e-07]]\n",
            "Are the outputs close?: True\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "# Define a dummy input\n",
        "dummy_input = torch.randn(1, 5)\n",
        "\n",
        "# Compare PyTorch and ONNX outputs\n",
        "compare_pytorch_onnx(model, onnx_file_path, dummy_input)"
      ],
      "metadata": {
        "id": "A3iTo_GzPOHK",
        "outputId": "ce17ec85-bfde-47b5-a42d-00aec0c54630",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 22,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "PyTorch Model Output: [[0.9473942]]\n",
            "ONNX Model Output: [[0.947394]]\n",
            "Difference: [[1.7881393e-07]]\n",
            "Are the outputs close?: True\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "# Define a dummy input\n",
        "dummy_input = torch.randn(1, 5)\n",
        "\n",
        "# Compare PyTorch and ONNX outputs\n",
        "compare_pytorch_onnx(model, onnx_file_path, dummy_input)"
      ],
      "metadata": {
        "id": "78vIamO2PdGE",
        "outputId": "ae7743e0-92df-4671-f383-f5d857f2c515",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 23,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "PyTorch Model Output: [[1.0613629]]\n",
            "ONNX Model Output: [[1.0613629]]\n",
            "Difference: [[0.]]\n",
            "Are the outputs close?: True\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "mERP1XH5PfSk"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}