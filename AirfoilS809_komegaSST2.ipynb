{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyOnaRfhiyFIFlJJJd9H8JcU",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/sudeepmenon17/PytorchforNN/blob/main/AirfoilS809_komegaSST2.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Xl1LRIq7N8yR"
      },
      "outputs": [],
      "source": [
        "!pip install google-auth\n",
        "from google.colab import auth\n",
        "from google.colab import drive\n",
        "\n",
        "drive.mount('/content/drive')\n",
        "# !ls /content/drive/MyDrive/"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "import pandas as pd\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "import matplotlib.pyplot as plt\n",
        "%matplotlib inline"
      ],
      "metadata": {
        "id": "rSfYBUai3kHp"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Create a Model class\n",
        "class Model(nn.Module):\n",
        "  def __init__(self,in_features=5, h1 = 61, h2 = 60, out_features=1):\n",
        "    super().__init__()\n",
        "    self.fc1 = nn.Linear(in_features,h1)\n",
        "    # self.dropout1 = nn.Dropout(0.05)\n",
        "    self.fc2 = nn.Linear(h1,h2)\n",
        "    # self.dropout2 = nn.Dropout(0.05)\n",
        "    # self.fc3 = nn.Linear(h2,h3)\n",
        "    # self.dropout3 = nn.Dropout(0.25)\n",
        "    self.out = nn.Linear(h2,out_features)\n",
        "\n",
        "  def forward(self,x):\n",
        "    x = F.sigmoid(self.fc1(x))\n",
        "    # x = self.dropout1(x)\n",
        "    x = F.sigmoid(self.fc2(x))\n",
        "    # x = self.dropout2(x)\n",
        "    # x = F.sigmoid(self.fc3(x))\n",
        "    # x = self.dropout3(x)\n",
        "    x = self.out(x)\n",
        "\n",
        "    return x\n",
        "\n",
        "torch.manual_seed(42)\n",
        "\n",
        "model = Model()"
      ],
      "metadata": {
        "id": "RbXIiz-K3tc6"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Read the data set -  Airfoil S809\n",
        "df1 = pd.read_csv(\"/content/drive/MyDrive/NN_features_for_training/data_set1.csv\")\n",
        "df2 = pd.read_csv(\"/content/drive/MyDrive/NN_features_for_training/data_set2.csv\")\n",
        "df3 = pd.read_csv(\"/content/drive/MyDrive/NN_features_for_training/data_set3.csv\")\n",
        "df4 = pd.read_csv(\"/content/drive/MyDrive/NN_features_for_training/data_set4.csv\")"
      ],
      "metadata": {
        "id": "a01YsiE83xHj"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Combine data\n",
        "frames = [df1, df2, df3, df4]\n",
        "ff = []\n",
        "j = 0\n",
        "for item in frames:\n",
        "  j = j+1\n",
        "  xc = np.array(item['x'])\n",
        "  yc = np.array(item['y'])\n",
        "  b = np.array(item['betaFieldInversion'])\n",
        "  ff1 = np.array(item['feature1'])\n",
        "  ff2 = np.array(item['feature2'])\n",
        "  ff3 = np.array(item['feature3'])\n",
        "  ff4 = np.array(item['feature4'])\n",
        "  ff5 = np.array(item['feature5'])\n",
        "\n",
        "\n",
        "  # # Normalize x and y coordinates\n",
        "  # min_range = -5.0\n",
        "  # max_range = 5.0\n",
        "  # xc = (xc - np.min(xc)) * (max_range - min_range) / (np.max(xc) - np.min(xc))\n",
        "  # yc = (yc - np.min(yc)) * (max_range - min_range) / (np.max(yc) - np.min(yc))\n",
        "\n",
        "\n",
        "\n",
        "  x1,y1,b1,f1,f2,f3,f4,f5,f6 = [[] for i in range(9)]\n",
        "  # Filter data for the specified range of coordinates\n",
        "  for i in range(len(xc)):\n",
        "    if xc[i]>=-0.2 and xc[i]<=1.0:\n",
        "      if yc[i]>=-0.15 and yc[i]<=0.20:\n",
        "        x1.append(xc[i])\n",
        "        y1.append(yc[i])\n",
        "        b1.append(b[i])\n",
        "        f1.append(ff1[i])\n",
        "        f2.append(ff2[i])\n",
        "        f3.append(ff3[i])\n",
        "        f4.append(ff4[i])\n",
        "        f5.append(ff5[i])\n",
        "\n",
        "\n",
        "\n",
        "  modified_data = {\n",
        "  'x': np.array(x1),\n",
        "  'y': np.array(y1),\n",
        "  'beta': np.array(b1),\n",
        "  'feature1': np.array(f1),\n",
        "  'feature2': np.array(f2),\n",
        "  'feature3': np.array(f3),\n",
        "  'feature4': np.array(f4),\n",
        "  'feature5': np.array(f5),\n",
        "  }\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "  cf = pd.DataFrame(modified_data)\n",
        "  # Data for beta>1.005 or beta<0.995\n",
        "  s1 = cf[(cf['beta'] < 0.995) | (cf['beta'] > 1.005)]\n",
        "  s2 = cf[(cf['beta'] >= 0.995) & (cf['beta'] <= 1.005)]\n",
        "\n",
        "\n",
        "  s3 = s2.sample(frac=0.25, random_state=1)\n",
        "  df_filtered = pd.concat([s1, s3], ignore_index=True)\n",
        "\n",
        "  # df_filtered.shape[0], s1.shape[0], s2.shape[0], s3.shape[0]\n",
        "\n",
        "  ax = df_filtered.plot.scatter(x='x',\n",
        "                      y='y',\n",
        "                      c='beta',\n",
        "                      colormap='RdYlGn')\n",
        "\n",
        "  ff.append(df_filtered)\n",
        "\n",
        "df = pd.concat(ff)"
      ],
      "metadata": {
        "id": "dCSahTCE4TR_"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import seaborn as sns\n",
        "import matplotlib.pyplot as plt\n",
        "import warnings\n",
        "warnings.filterwarnings('ignore')\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "df1 = df.drop(['x','y','beta'],axis=1)\n",
        "df2 = df.drop(['x','y','feature1','feature2','feature3','feature4','feature5'],axis=1)\n",
        "\n",
        "\n",
        "plt.figure(figsize=(20,5))\n",
        "plt.subplot(1,3,1)\n",
        "sns.distplot(df1['feature1'])\n",
        "plt.subplot(1,3,2)\n",
        "sns.distplot(df1['feature2'])\n",
        "plt.subplot(1,3,3)\n",
        "sns.distplot(df1['feature3'])\n",
        "\n",
        "plt.figure(figsize=(20,5))\n",
        "plt.subplot(1,3,1)\n",
        "sns.distplot(df1['feature4'])\n",
        "plt.subplot(1,3,2)\n",
        "sns.distplot(df1['feature5'])\n",
        "# plt.subplot(1,3,3)\n",
        "# sns.distplot(df1['feature6'])"
      ],
      "metadata": {
        "id": "z0uFyApL4Y8b"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.preprocessing import StandardScaler\n",
        "from sklearn.preprocessing import MinMaxScaler\n",
        "from sklearn.preprocessing import PowerTransformer\n",
        "from sklearn.preprocessing import QuantileTransformer\n",
        "from sklearn.preprocessing import Normalizer\n",
        "from sklearn.preprocessing import RobustScaler\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "# # Fill missing values with the mean\n",
        "# df1 = df1.fillna(df1.mean())\n",
        "# m = df1.max()\n",
        "# df1 = df1.div(m)\n",
        "\n",
        "# df1.min(),df1.max()\n",
        "# Standardization\n",
        "# standard_scaler = StandardScaler()\n",
        "# min_max_scaler = MinMaxScaler(feature_range=(0, 1))\n",
        "# # transformer = Normalizer()\n",
        "# scaler = RobustScaler(with_centering=False)\n",
        "\n",
        "# Features\n",
        "# X = min_max_scaler.fit_transform(df1)\n",
        "X = df1.values\n",
        "\n",
        "# # Target\n",
        "# # y = df_filtered['beta'].values\n",
        "# # y = standard_scaler.fit_transform(df2)\n",
        "# min_max_scaler = MinMaxScaler(feature_range=(0, 1))\n",
        "# y = min_max_scaler.fit_transform(df2)\n",
        "# # y = scaler.fit_transform(df2)\n",
        "y = df2.values"
      ],
      "metadata": {
        "id": "BHOo9gCLXlY9"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "criterion = nn.MSELoss()\n",
        "optimizer = torch.optim.Adam(model.parameters(),lr = 0.001,weight_decay=0.0000001)\n",
        "# optimizer = torch.optim.SGD(model.parameters(),lr = 0.001,weight_decay=0.0)"
      ],
      "metadata": {
        "id": "H4fZ5XOCXtp0"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#5-Fold Cross Validation\n",
        "from sklearn import metrics\n",
        "\n",
        "from sklearn.model_selection import KFold\n",
        "kFold=KFold(n_splits=5,shuffle=True, random_state=100)\n",
        "\n",
        "# Initialize a list to store the evaluation scores\n",
        "scores = []\n",
        "training_cost = []\n",
        "testing_cost =[]\n",
        "iterations = 1000\n",
        "train_fold = [[] for i in range(8)]\n",
        "test_fold = [[] for i in range(8)]\n",
        "c = 0\n",
        "for train_index,test_index in kFold.split(X):\n",
        "  print(\"Train Index: \", train_index, \"\\n\")\n",
        "  print(\"Test Index: \", test_index)\n",
        "  print(\"Size of training data:\", len(train_index),\"\\n\")\n",
        "  print(\"Size of testing data:\", len(test_index),\"\\n\")\n",
        "\n",
        "  X_train, X_test, y_train, y_test = X[train_index], X[test_index], y[train_index], y[test_index]\n",
        "\n",
        "\n",
        "  X_train = torch.FloatTensor(X_train)\n",
        "  X_test = torch.FloatTensor(X_test)\n",
        "\n",
        "  y_train = torch.FloatTensor(y_train)\n",
        "  y_test = torch.FloatTensor(y_test)\n",
        "\n",
        "\n",
        "  losses = []\n",
        "  for i in range(iterations):\n",
        "    # go forward and predict\n",
        "    y_pred = model.forward(X_train)\n",
        "\n",
        "    # Measure the loss\n",
        "    loss = criterion(y_pred,y_train)\n",
        "\n",
        "    # Keep track of the losses\n",
        "    losses.append(loss.detach().numpy())\n",
        "\n",
        "    # print every 10 epoch\n",
        "    if i % 10 == 0:\n",
        "      print(f'iter: {i} and loss: {loss}')\n",
        "\n",
        "    # Backpropagation\n",
        "    optimizer.zero_grad()\n",
        "    loss.backward()\n",
        "    optimizer.step()\n",
        "  train_fold[c].append(y_pred.detach().numpy())\n",
        "  train_fold[c].append(y_train.detach().numpy())\n",
        "  training_cost.append(losses)\n",
        "\n",
        "  # Evaluate Model\n",
        "  with torch.no_grad():\n",
        "    y_eval = model.forward(X_test)\n",
        "    test_loss = criterion(y_eval,y_test)\n",
        "  test_fold[c].append(y_eval.detach().numpy())\n",
        "  test_fold[c].append(y_test.detach().numpy())\n",
        "\n",
        "\n",
        "  testing_cost.append(test_loss)\n",
        "  scores.append(metrics.mean_squared_error(y_eval,y_test))\n",
        "  print('MSEloss: {}'.format(testing_cost))\n",
        "  print('MSE error: {}'.format(scores))\n",
        "\n",
        "  from sklearn.metrics import r2_score\n",
        "\n",
        "  r2 = r2_score(y_test,y_eval)\n",
        "  print(f\"R-squared value = {r2}\")\n",
        "\n",
        "  c = c+1"
      ],
      "metadata": {
        "id": "AhfaheHHXxaq"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.metrics import r2_score\n",
        "\n",
        "r2 = r2_score(y_test,y_eval)\n",
        "print(f\"R-squared value = {r2}\")\n"
      ],
      "metadata": {
        "id": "NVjLyDx0X2v_"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Define the coordinates for the diagonal line\n",
        "a1 = [0.9, 1.7]  # x-coordinates of the line's endpoints\n",
        "b1 = [0.9, 1.7]  # y-coordinates of the line's endpoints\n",
        "\n",
        "plt.figure(figsize=(12,4))\n",
        "plt.subplot(1,2,1)\n",
        "plt.scatter(train_fold[0][1],train_fold[0][0], s=5)\n",
        "plt.plot(a1, b1, color='red')\n",
        "plt.xlabel(r'$\\beta$-truth')\n",
        "plt.ylabel(r'$\\beta$-predicted')\n",
        "plt.title('Initial Training')\n",
        "\n",
        "\n",
        "# plt.subplot(1,8,2)\n",
        "# plt.scatter(train_fold[1][1],train_fold[1][0], s=5)\n",
        "# plt.xlabel('True')\n",
        "# plt.ylabel('Predicted')\n",
        "# plt.title('Training - Fold2')\n",
        "# plt.subplot(1,8,3)\n",
        "# plt.scatter(train_fold[2][1],train_fold[2][0], s=5)\n",
        "# plt.xlabel('True')\n",
        "# plt.ylabel('Predicted')\n",
        "# plt.title('Training - Fold3')\n",
        "# plt.subplot(1,8,4)\n",
        "# plt.scatter(train_fold[3][1],train_fold[3][0], s=5)\n",
        "# plt.xlabel('True')\n",
        "# plt.ylabel('Predicted')\n",
        "# plt.title('Training - Fold4')\n",
        "# plt.subplot(1,8,5)\n",
        "# plt.scatter(train_fold[4][1],train_fold[4][0], s=5)\n",
        "# plt.xlabel('True')\n",
        "# plt.ylabel('Predicted')\n",
        "# plt.title('Training - Fold5')\n",
        "# # plt.ylim(-4,2)\n",
        "\n",
        "\n",
        "# plt.subplot(1,8,6)\n",
        "# plt.scatter(train_fold[5][1],train_fold[5][0], s=5)\n",
        "# plt.xlabel('True')\n",
        "# plt.ylabel('Predicted')\n",
        "# plt.title('Training - Fold6')\n",
        "# # plt.ylim(-4,2)\n",
        "# plt.subplot(1,8,7)\n",
        "# plt.scatter(train_fold[6][1],train_fold[6][0], s=5)\n",
        "# plt.xlabel('True')\n",
        "# plt.ylabel('Predicted')\n",
        "# plt.title('Training - Fold7')\n",
        "# # plt.ylim(-4,2)\n",
        "plt.subplot(1,2,2)\n",
        "plt.scatter(train_fold[2][1],train_fold[2][0], s=5)\n",
        "plt.plot(a1, b1, color='red')\n",
        "plt.xlabel(r'$\\beta$-truth')\n",
        "plt.ylabel(r'$\\beta$-predicted')\n",
        "plt.title('Final Training')\n",
        "# plt.ylim(-4,2)\n",
        "plt.show()\n",
        "\n",
        "plt.figure(figsize=(12,4))\n",
        "plt.subplot(1,2,1)\n",
        "plt.scatter(test_fold[0][1],test_fold[0][0],s =5 )\n",
        "plt.plot(a1, b1, color='red')\n",
        "plt.xlabel(r'$\\beta$-truth')\n",
        "plt.ylabel(r'$\\beta$-predicted')\n",
        "plt.title('Initial Testing')\n",
        "# plt.subplot(1,8,2)\n",
        "# plt.scatter(test_fold[1][1],test_fold[1][0],s =5 )\n",
        "# plt.xlabel('True')\n",
        "# plt.ylabel('Predicted')\n",
        "# plt.title('Testing- Fold2')\n",
        "# plt.subplot(1,8,3)\n",
        "# plt.scatter(test_fold[2][1],test_fold[2][0],s =5 )\n",
        "# plt.xlabel('True')\n",
        "# plt.ylabel('Predicted')\n",
        "# plt.title('Testing- Fold3')\n",
        "# plt.subplot(1,8,4)\n",
        "# plt.scatter(test_fold[3][1],test_fold[3][0],s =5 )\n",
        "# plt.xlabel('True')\n",
        "# plt.ylabel('Predicted')\n",
        "# plt.title('Testing- Fold4')\n",
        "# plt.subplot(1,8,5)\n",
        "# plt.scatter(test_fold[4][1],test_fold[4][0],s =5 )\n",
        "# plt.xlabel('True')\n",
        "# plt.ylabel('Predicted')\n",
        "# plt.title('Testing- Fold5')\n",
        "\n",
        "# plt.subplot(1,8,6)\n",
        "# plt.scatter(test_fold[5][1],test_fold[5][0],s =5 )\n",
        "# plt.xlabel('True')\n",
        "# plt.ylabel('Predicted')\n",
        "# plt.title('Testing- Fold6')\n",
        "# plt.subplot(1,8,7)\n",
        "# plt.scatter(test_fold[6][1],test_fold[6][0],s =5 )\n",
        "# plt.xlabel('True')\n",
        "# plt.ylabel('Predicted')\n",
        "# plt.title('Testing- Fold7')\n",
        "plt.subplot(1,2,2)\n",
        "plt.scatter(test_fold[2][1],test_fold[2][0],s =5 )\n",
        "plt.plot(a1, b1, color='red')\n",
        "plt.xlabel(r'$\\beta$-truth')\n",
        "plt.ylabel(r'$\\beta$-predicted')\n",
        "plt.title('Final Testing')\n",
        "\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "NlugE7OL1c8x"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "TFc7u_9t1dzB"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}